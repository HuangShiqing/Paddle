/* Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License. */

#ifdef PADDLE_WITH_XPU_KP
#include <xpu/runtime.h>  // NOLINT
#include <algorithm>
#include <ctime>
#include <memory>
#include <numeric>

#include "paddle/fluid/framework/fleet/box_wrapper_kernel.h"
#include "paddle/fluid/platform/device_context.h"
#include "xpu/kernel/cluster_header.h"  // NOLINT
// #include "xpu/kernel/debug.h"           // NOLINT
#include "xpu/kernel/math.h"            // NOLINT
#include "xpu/kernel/simd.h"

namespace paddle {
namespace framework {

struct EmbedxQuantOp {
  __device__ void copy(float* dest, const float* src,
                                       const int& idx,
                                       const float& scale) const {
    *dest = *(reinterpret_cast<const int16_t*>(src) + idx) * scale;
  }
};
struct EmbedxNormalOp {
  __device__ void copy(float* dest, const float* src,
                                       const int& idx,
                                       const float& /**scale*/) const {
    *dest = src[idx];
  }
};

template <typename T>
__device__ void set_byfloat(float* dest, const T& val) {
  (*reinterpret_cast<T*>(dest)) = val;
}

__global__ void CopyKeysKernel(unsigned long long* src_keys,
                               uint32_t* dest_total_keys,
                               const long long* len, int slot_num,
                               int total_len, int* key2slots) {
  int cid = core_id();
  int ncores = core_num();
  if (cid >= ncores) {
    return;
  }
  int thread_id = ncores * cluster_id() + cid;
  int nthreads = ncores * cluster_num();
  __local__ long long local_len[slot_num];
  GM2LM(len, local_len, slot_num * sizeof(long long));

  __global_ptr__ unsigned long long* local_keys[slot_num];
  GM2LM(src_keys, local_keys,
        slot_num * sizeof(__global_ptr__ unsigned long long*));

  for (int i = thread_id; i < slot_num; i += nthreads) {
    // max core local memory = 8KB
    int slot_len = i ? local_len[i] - local_len[i - 1] : local_len[0];
    // int read_len = min(slot_len, 1024);
    int read_len = 100;
    int dest_len = i ? local_len[i - 1] : 0;
    __local__ unsigned long long local_slot_keys[read_len];
    __local__ uint32_t local_slot_keys_uint32[read_len];

    for (int k = 0; k < slot_len; k += read_len) {
      int real_read_len = min(read_len, slot_len - k);
      GM2LM(local_keys[i] + k, local_slot_keys,
            real_read_len * sizeof(unsigned long long));
      for (int m = 0; m < real_read_len; m++) {
          local_slot_keys_uint32[m] = (uint32_t)local_slot_keys[m];
      }
      mfence();
      LM2GM(&i, key2slots + dest_len + k, sizeof(int));
      LM2GM(local_slot_keys_uint32, dest_total_keys + dest_len + k,
            real_read_len * sizeof(uint32_t));
    }
  }
}

void BoxWrapperKernel::CopyKeys(const paddle::platform::Place& place,
                            uint64_t** origin_keys, uint32_t* total_keys,
                            const int64_t* gpu_len, int slot_num,
                            int total_len, int* key2slots) {
  XPUStream stream = nullptr;
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  stream = static_cast<platform::XPUDeviceContext*>(dev_ctx)
               ->x_context()
               ->xpu_stream;
  unsigned long long* o_keys =
      reinterpret_cast<unsigned long long*>(origin_keys);
  const long long* c_len = (const long long*)gpu_len;
  CopyKeysKernel<<<2, 64, stream>>>(o_keys, total_keys, c_len, slot_num, total_len, key2slots);
  xpu_wait(stream);
}

template <typename TEmbedxOp>
__global__ void PullCopy(const TEmbedxOp* op,
                          const float scale,
                          const boxps::FeaturePullOffset* info,
                          int* total_dims,
                          float* dst_vals,
                          // uint64_t* total_keys,
                          float* total_values,
                          const uint32_t* restore_idx,
                          const int total_length,
                          const int hidden_size,
                          const int pull_float_num,
                          const int skip_offset,
                          const int cvm_offset) {
  int cid = core_id();
  int ncores = core_num();
  if (cid >= ncores) {
      return;
  }
  int thread_id = cluster_id() * ncores + cid;
  int nthreads = cluster_num() * ncores;

  const int buf_length = 50; // max 2048 float
  int per_thread_len = roundup_div(total_length, nthreads);
  int per_thread_loop_count = roundup_div(per_thread_len, buf_length);
  int per_thread_per_loop_len = roundup_div(per_thread_len, per_thread_loop_count);

  __local__ float lm_total_values[buf_length * pull_float_num];
  __local__ float lm_dst_vals[buf_length * hidden_size];
  __local__ int lm_total_dims[buf_length];
  __local__ uint32_t lm_restore_idx[buf_length];
  __local__ boxps::FeaturePullOffset lm_info[1];
  __local__ TEmbedxOp lm_op[1];

  GM2LM(info, lm_info, sizeof(boxps::FeaturePullOffset));
  GM2LM(op, lm_op, sizeof(TEmbedxOp));
  for (int i = thread_id; i < per_thread_loop_count * nthreads; i += nthreads) {
    int gm_offset = i * per_thread_per_loop_len;
    if (gm_offset >= total_length)
      return;
    if(restore_idx != nullptr)
      GM2LM(restore_idx + gm_offset, lm_restore_idx, per_thread_per_loop_len * sizeof(uint32_t));
    int pos = (restore_idx != nullptr) ? lm_restore_idx[gm_offset] : gm_offset;
    GM2LM(total_values + pos * pull_float_num, lm_total_values, per_thread_per_loop_len * pull_float_num * sizeof(float));
    GM2LM(dst_vals + gm_offset * hidden_size, lm_dst_vals, per_thread_per_loop_len * hidden_size * sizeof(float));
    GM2LM(total_dims + gm_offset, lm_total_dims, per_thread_per_loop_len * sizeof(int));

    int len = min(per_thread_per_loop_len, total_length - gm_offset);
    for (int j = 0; j < len; j++) {
      for (int k = 0; k < cvm_offset; ++k) {
        // dest_ptr[k] = src_val[info->show + k + skip_offset];
        lm_dst_vals[j * hidden_size + k] = lm_total_values[j * pull_float_num + lm_info[0].show + skip_offset + k];
      }
      // embedx
      int embedx_size = lm_total_values[j * pull_float_num + lm_info[0].embedx_size];
      lm_total_dims[j] = (int)(embedx_size > 0);
      for (int k = 0; k < embedx_size; ++k) {
        // lm_dst_vals[j * hidden_size + cvm_offset + k]
        // lm_total_values[j * pull_float_num + info->embedx]+k
        // op.copy(&dest_ptr[cvm_offset + k], &src_val[info->embedx], k, scale);
        lm_op[0].copy(lm_dst_vals + j * hidden_size + cvm_offset + k,
                lm_total_values + j * pull_float_num + lm_info[0].embedx,
                k,
                scale);
      }
      int dim_size = hidden_size - cvm_offset;
      for (int k = embedx_size; k < dim_size; ++k) {
        // dest_ptr[cvm_offset + k] = 0;
        lm_dst_vals[j * hidden_size + cvm_offset + k] = 0;
      }
    }
    mfence();// mfence_lm();
    LM2GM(lm_dst_vals, dst_vals + gm_offset * hidden_size, len * sizeof(float) * hidden_size);
    LM2GM(lm_total_dims, total_dims + gm_offset, len * sizeof(int));
  }
}

// template <typename TEmbedxOp>
// inline void FeaturePullCopy(
//     const TEmbedxOp& op, const boxps::FeaturePullOffset* info,
//     const size_t& pull_float_num, XPUStream stream, uint64_t** gpu_keys,
//     float** gpu_values, void* src, const int hidden_size,
//     const size_t embedx_dim, const size_t total_length, int* total_dims,
//     const int64_t* slot_lens, const int slot_num, const int* key2slot,
//     const float scale, const int cvm_offset, const uint32_t* gpu_restore_idx,
//     const int skip_offset) {
template <typename TEmbedxOp>
inline void FeaturePullCopy(const paddle::platform::Place& place,
                            const TEmbedxOp* op,
                            const float scale,
                            XPUStream stream,
                            const boxps::FeaturePullOffset* info,
                            int* total_dims,
                            float** xpu_values,// const std::vector<float*>& values,
                            uint64_t* total_keys_xpu,
                            float* total_values_xpu,
                            const uint32_t* xpu_restore_idx,
                            const int64_t* slot_lens,
                            const int slot_num,
                            const int total_length,
                            const int hidden_size,
                            const int pull_float_num,
                            const int skip_offset,
                            const int cvm_offset){
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();

  float* dst_vals = nullptr;
  auto dst_vals_tmp =
    memory::Alloc(place, total_length * sizeof(float) * hidden_size);
  dst_vals = reinterpret_cast<float*>(dst_vals_tmp->ptr());

  PullCopy<TEmbedxOp><<<8, 64>>>(op,
                                scale,
                                info,
                                total_dims,
                                dst_vals,
                                // total_keys_xpu,
                                total_values_xpu,
                                xpu_restore_idx,
                                total_length,
                                hidden_size,
                                pull_float_num,
                                skip_offset,
                                cvm_offset);
  // int r = xpu::pull_copy<xpu::FeatureValue>(
  //   ctx_xpu,
  //   dst_vals,
  //   total_keys,
  //   reinterpret_cast<xpu::FeatureValue*>(total_values_gpu),
  //   total_length,
  //   hidden_size);
  // PADDLE_ENFORCE_EQ(
  //   r, XPU_SUCCESS,
  //   platform::errors::External("XPU pull_copy kernel return wrong value[%d %s]",
  //                               r, XPUAPIErrorMsg[r]));
  // for (int i = 0; i < slot_num; i++) {
  //   int slot_len = i ? slot_lens[i] - slot_lens[i - 1] : slot_lens[0];
  //   int offset = i ? slot_lens[i-1] : 0;
  //   xpu::copy<float>(ctx_xpu, dst_vals + offset * hidden_size, xpu_values[i], slot_len * hidden_size);
  //   // PADDLE_ENFORCE_XDNN_SUCCESS(
  //   //   xpu::copy<float>(ctx_xpu, dst_vals + offset * hidden_size, xpu_values[i],
  //   //     slot_len * hidden_size), "copy");
  // }
}

void BoxWrapperKernel::CopyForPull(
    const paddle::platform::Place& place, uint64_t** gpu_keys,
    float** xpu_values, void* total_values_xpu,
    boxps::FeaturePullOffset* pull_offset, const int64_t* slot_lens,
    const int slot_num, const int* key2slot, const int hidden_size,
    const int expand_embed_dim, const int64_t total_length, int* total_dims,
    const int skip_offset, bool expand_only, const uint32_t* xpu_restore_idx) {
// void BoxWrapperKernel::CopyForPull(const paddle::platform::Place& place,
//                                    boxps::FeaturePullOffset* pull_offset,
//                                    int* total_dims,
//                                    float** xpu_values,
//                                    uint64_t* total_keys_xpu,
//                                    void* total_values_xpu,
//                                    const int64_t* slot_lens,
//                                    const int slot_num,
//                                    const int64_t total_length,
//                                    const int hidden_size,
//                                    const int skip_offset,
//                                    const uint32_t* xpu_restore_idx) {
  // TODO: for test
  return;

  uint64_t* total_keys_xpu = nullptr;
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto stream = static_cast<platform::XPUDeviceContext*>(dev_ctx)
               ->x_context()
               ->xpu_stream;
  const int cvm_offset = cvm_offset_ - skip_offset;
  if (pull_info_.is_quant) {
    EmbedxQuantOp op;
    // FeaturePullCopy(op, pull_offset, pull_float_num_, stream, gpu_keys,
    //                 gpu_values, total_values_gpu, hidden_size, embedx_dim_,
    //                 total_length, total_dims, slot_lens, slot_num, key2slot,
    //                 pull_embedx_scale_, cvm_offset, gpu_restore_idx,
    //                 skip_offset);
    FeaturePullCopy(place,
                    &op,
                    pull_embedx_scale_,
                    stream,
                    pull_offset,
                    total_dims,
                    xpu_values,
                    total_keys_xpu,
                    (float*)total_values_xpu,
                    xpu_restore_idx,
                    slot_lens,
                    slot_num,
                    (int)total_length,
                    hidden_size,
                    (int)pull_float_num_,
                    skip_offset,
                    cvm_offset);
  } else {
    EmbedxNormalOp op;
    // normal and adam
    // FeaturePullCopy(op, pull_offset, pull_float_num_, stream, gpu_keys,
    //                 gpu_values, total_values_gpu, hidden_size, embedx_dim_,
    //                 total_length, total_dims, slot_lens, slot_num, key2slot,
    //                 pull_embedx_scale_, cvm_offset, gpu_restore_idx,
    //                 skip_offset);
    FeaturePullCopy(place,
                    &op,
                    pull_embedx_scale_,
                    stream,
                    pull_offset,
                    total_dims,
                    xpu_values,
                    total_keys_xpu,
                    (float*)total_values_xpu,
                    xpu_restore_idx,
                    slot_lens,
                    slot_num,
                    total_length,
                    hidden_size,
                    pull_float_num_,
                    skip_offset,
                    cvm_offset);
  }
  xpu_wait(stream);
}

__global__ void PushCopy(float* src_vals,
    float* dest_vals,
    boxps::FeaturePushOffset* push_offset,
    const int push_float_num,
    const int total_length,
    const int hidden_size,
    const int batch_size,
    const int* total_dims,
    const int skip_offset,
    const int cvm_offset,
    const int* key2slot) {
    int cid = core_id();
    int ncores = core_num();
    if (cid >= ncores) {
      return;
    }
    int thread_id = cluster_id() * ncores + cid;
    int nthreads = cluster_num() * ncores;

    const int buf_length = 40; // max 2048 float
    int per_thread_len = roundup_div(total_length, nthreads);
    int per_thread_loop_count = roundup_div(per_thread_len, buf_length);
    int per_thread_per_loop_len =
      roundup_div(per_thread_len, per_thread_loop_count);

    __local__ float lm_src_vals[buf_length * hidden_size];
    __local__ float lm_dest_vals[buf_length * push_float_num];
    __local__ int lm_total_dims[buf_length];
    __local__ int lm_key2slot[buf_length];
    boxps::FeaturePushOffset info;

    GM2LM(push_offset, &info, sizeof(boxps::FeaturePushOffset));

    float scale = -1. * batch_size;
    for (int i = thread_id; i < per_thread_loop_count * nthreads; i += nthreads) {
      int gm_offset = i * per_thread_per_loop_len;
      if (gm_offset >= total_length)
        return;

      GM2LM(src_vals + gm_offset * hidden_size, lm_src_vals,
              per_thread_per_loop_len * hidden_size * sizeof(float));
      GM2LM(dest_vals + gm_offset * push_float_num, lm_dest_vals,
              per_thread_per_loop_len * push_float_num * sizeof(float));
      GM2LM(total_dims + gm_offset, lm_total_dims,
              per_thread_per_loop_len * sizeof(int));
      GM2LM(key2slot + gm_offset, lm_key2slot,
              per_thread_per_loop_len * sizeof(int));

      int count_per_loop =
        min(per_thread_per_loop_len, total_length - gm_offset);

      for (int j = 0; j < count_per_loop; j++) {
          float* dest_val = lm_dest_vals + j * push_float_num;
          set_byfloat<int>(dest_val + info.slot, lm_key2slot[j]);

          float* optr = reinterpret_cast<float*>(&dest_val[info.show]);
          float* src_val = reinterpret_cast<float*>(lm_src_vals + j * hidden_size);

          for (int k = 0; k < skip_offset; ++k) {
              optr[k] = 1.0;
          }
          for (int k = 0; k < cvm_offset; ++k) {
              optr[k + skip_offset] = src_val[k];
          }
          for (int k = 0; k < info.embed_num; ++k) {
              dest_val[info.embed_g + k] *= -1. * batch_size;
          }
          if (lm_total_dims[j] & 0x01) {
              for (int k = 0; k < hidden_size - cvm_offset; ++k) {
                  dest_val[info.embedx_g + k] = src_val[cvm_offset + k] * -1. * batch_size;
              }
          } else {
              for (int k = 0; k < hidden_size - cvm_offset; ++k) {
                  dest_val[info.embedx_g + k] = 0;
              }
          }
      }
  }
}

void BoxWrapperKernel::CopyForPush(
    const paddle::platform::Place& place,
    float* gm_src_ptr,
    void* total_grad_values_xpu,
    boxps::FeaturePushOffset* push_offset,
    const int64_t total_length,
    const int* slots,
    const int64_t* slot_lens,
    const int slot_num,
    const int hidden_size,
    const int batch_size,
    const int* total_dims,
    const int skip_offset,
    const int* key2slot) {
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto stream = static_cast<platform::XPUDeviceContext*>(dev_ctx)
               ->x_context()
               ->xpu_stream;

  const int cvm_offset = cvm_offset_ - skip_offset;

  const int c_total_length = static_cast<const int>(total_length);
  float* push_grad_values = reinterpret_cast<float*>(total_grad_values_xpu);

  // TODO: slots, slot_lens, slot_num can be removed?
  PushCopy<<<8, 64, stream>>>(gm_src_ptr, push_grad_values, push_offset,
      push_float_num_, c_total_length, hidden_size, batch_size, total_dims,
      skip_offset, cvm_offset, key2slot);

  xpu_wait(stream);
}

void BoxWrapperKernel::GetFeatureInfo(boxps::FeaturePullOffset &pull_info,
    size_t feature_pull_size, boxps::FeaturePushOffset &push_info,
    size_t feature_push_size, int embedx_dim, int expand_embed_dim,
    float pull_embedx_scale) {
  pull_info_ = pull_info;
  feature_pull_size_ = feature_pull_size;
  push_info_ = push_info;
  feature_push_size_ = feature_push_size;

  pull_float_num_ = feature_pull_size_ / sizeof(float);
  push_float_num_ = feature_push_size_ / sizeof(float);
  // set cvm offset
  cvm_offset_ = pull_info_.embedx_size - pull_info_.show;

  embedx_dim_ = embedx_dim;
  expand_embed_dim_ = expand_embed_dim;
  pull_embedx_scale_ = pull_embedx_scale;
}

}  // end namespace framework
}  // end namespace paddle
#endif