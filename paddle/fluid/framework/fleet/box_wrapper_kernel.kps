/* Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License. */

#ifdef PADDLE_WITH_XPU_KP
#include <xpu/runtime.h>  // NOLINT
#include <algorithm>
#include <ctime>
#include <memory>
#include <numeric>

#include "paddle/fluid/framework/fleet/box_wrapper_kernel.h"
#include "paddle/fluid/platform/device_context.h"
// #include "paddle/fluid/framework/lod_tensor.h"
#include "xpu/kernel/cluster_header.h"  // NOLINT
//#include "xpu/kernel/debug.h"           // NOLINT
#include "xpu/kernel/math.h"            // NOLINT
#include "xpu/kernel/simd.h"

namespace paddle {
namespace framework {

struct EmbedxQuantOp {
  __device__ void copy(float* dest, const float* src,
                                       const int& idx,
                                       const float& scale) const {
    *dest = *(reinterpret_cast<const int16_t*>(src) + idx) * scale;
  }
};
struct EmbedxNormalOp {
  __device__ void copy(float* dest, const float* src,
                                       const int& idx,
                                       const float& /**scale*/) const {
    *dest = src[idx];
  }
};

__global__ void CopyKeysKernel(unsigned long long* src_keys,
                               uint32_t* dest_total_keys,
                               const long long* len, int slot_num,
                               int total_len) {
  int cid = core_id();
  int ncores = core_num();
  if (cid >= ncores) {
    return;
  }
  int thread_id = ncores * cluster_id() + cid;
  int nthreads = ncores * cluster_num();
  __local__ long long local_len[slot_num];
  GM2LM(len, local_len, slot_num * sizeof(long long));

  __global_ptr__ unsigned long long* local_keys[slot_num];
  GM2LM(src_keys, local_keys,
        slot_num * sizeof(__global_ptr__ unsigned long long*));

  for (int i = thread_id; i < slot_num; i += nthreads) {
    // max core local memory = 8KB
    int slot_len = i ? local_len[i] - local_len[i - 1] : local_len[0];
    // int read_len = min(slot_len, 1024);
    int read_len = 100;
    int dest_len = i ? local_len[i - 1] : 0;
    __local__ unsigned long long local_slot_keys[read_len];
    __local__ uint32_t local_slot_keys_uint32[read_len];

    for (int k = 0; k < slot_len; k += read_len) {
      int real_read_len = min(read_len, slot_len - k);
      GM2LM(local_keys[i] + k, local_slot_keys,
            real_read_len * sizeof(unsigned long long));
      for (int m = 0; m < real_read_len; m++) {
          local_slot_keys_uint32[m] = (uint32_t)local_slot_keys[m];
      }
      mfence();
      LM2GM(local_slot_keys_uint32, dest_total_keys + dest_len + k,
            real_read_len * sizeof(uint32_t));
    }
  }
}

void BoxWrapperKernel::CopyKeys(const paddle::platform::Place& place,
                            uint64_t** origin_keys, uint32_t* total_keys,
                            const int64_t* gpu_len, int slot_num,
                            int total_len) {
  XPUStream stream = nullptr;
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  stream = static_cast<platform::XPUDeviceContext*>(dev_ctx)
               ->x_context()
               ->xpu_stream;
  unsigned long long* o_keys =
      reinterpret_cast<unsigned long long*>(origin_keys);
  const long long* c_len = (const long long*)gpu_len;
  CopyKeysKernel<<<2, 64, stream>>>(o_keys, total_keys, c_len, slot_num, total_len);
  xpu_wait(stream);
}

template <typename TEmbedxOp>
inline void FeaturePullCopy(
    const TEmbedxOp& op, const boxps::FeaturePullOffset* info,
    const size_t& pull_float_num, XPUStream stream, uint64_t** gpu_keys,
    float** gpu_values, void* src, const int hidden_size,
    const size_t embedx_dim, const size_t total_length, int* total_dims,
    const int64_t* slot_lens, const int slot_num, const int* key2slot,
    const float scale, const int cvm_offset, const uint32_t* gpu_restore_idx,
    const int skip_offset) {
  // TODO:
  // float* dst_vals = nullptr;
  // auto dst_vals_tmp =
  //   memory::Alloc(place, total_length * sizeof(float) * hidden_size);
  // dst_vals = reinterpret_cast<float*>(dst_vals_tmp->ptr());

  // int r = xpu::pull_copy<xpu::FeatureValue>(
  //   ctx_xpu,
  //   dst_vals,
  //   total_keys,
  //   reinterpret_cast<xpu::FeatureValue*>(total_values_gpu),
  //   total_length,
  //   hidden_size);
  // PADDLE_ENFORCE_EQ(
  //   r, XPU_SUCCESS,
  //   platform::errors::External("XPU pull_copy kernel return wrong value[%d %s]",
  //                               r, XPUAPIErrorMsg[r]));

  // for (int i = 0; i < static_cast<int>(slot_lengths.size()); i++) {
  //   int slot_len =
  //     i ? slot_lengths_lod[i] - slot_lengths_lod[i - 1] : slot_lengths_lod[0];
  //   int offset = i ? slot_lengths_lod[i-1] : 0;
  //   PADDLE_ENFORCE_XDNN_SUCCESS(
  //     xpu::copy<float>(ctx_xpu, dst_vals + offset * hidden_size, values[i],
  //       slot_len * hidden_size), "copy");
  // }
}

void BoxWrapperKernel::CopyForPull(
    const paddle::platform::Place& place, uint64_t** gpu_keys,
    float** gpu_values, void* total_values_gpu,
    boxps::FeaturePullOffset* pull_offset, const int64_t* slot_lens,
    const int slot_num, const int* key2slot, const int hidden_size,
    const int expand_embed_dim, const int64_t total_length, int* total_dims,
    const int skip_offset, bool expand_only, const uint32_t* gpu_restore_idx) {
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto stream = static_cast<platform::XPUDeviceContext*>(dev_ctx)
               ->x_context()
               ->xpu_stream;
  const int cvm_offset = cvm_offset_ - skip_offset;
  if (pull_info_.is_quant) {
    EmbedxQuantOp op;
    FeaturePullCopy(op, pull_offset, pull_float_num_, stream, gpu_keys,
                    gpu_values, total_values_gpu, hidden_size, embedx_dim_,
                    total_length, total_dims, slot_lens, slot_num, key2slot,
                    pull_embedx_scale_, cvm_offset, gpu_restore_idx,
                    skip_offset);
  } else {
    EmbedxNormalOp op;
    // normal and adam
    FeaturePullCopy(op, pull_offset, pull_float_num_, stream, gpu_keys,
                    gpu_values, total_values_gpu, hidden_size, embedx_dim_,
                    total_length, total_dims, slot_lens, slot_num, key2slot,
                    pull_embedx_scale_, cvm_offset, gpu_restore_idx,
                    skip_offset);
  }
  xpu_wait(stream);
}

void BoxWrapperKernel::GetFeatureInfo(boxps::FeaturePullOffset &pull_info,
    size_t feature_pull_size, boxps::FeaturePushOffset &push_info,
    size_t feature_push_size, int embedx_dim, int expand_embed_dim,
    float pull_embedx_scale) {
  pull_info_ = pull_info;
  feature_pull_size_ = feature_pull_size;
  push_info_ = push_info;
  feature_push_size_ = feature_push_size;

  pull_float_num_ = feature_pull_size_ / sizeof(float);
  push_float_num_ = feature_push_size_ / sizeof(float);
  // set cvm offset
  cvm_offset_ = pull_info_.embedx_size - pull_info_.show;

  embedx_dim_ = embedx_dim;
  expand_embed_dim_ = expand_embed_dim;
  pull_embedx_scale_ = pull_embedx_scale;
}

}  // end namespace framework
}  // end namespace paddle
#endif